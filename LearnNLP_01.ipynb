{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prakashdassr/LearnNLP/blob/main/LearnNLP_01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Z04Vbcyu_MH",
        "outputId": "f2835d42-3104-4c6f-e5b3-4f3c35a1d328"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, I am ChatB, a AI language model here to assist you. Would you like to engage in a conversation with my counterpart,?\n",
            "what is machine learning\n",
            "chatB:  in the recent years, various machine learning applications have been developed, like model to \n",
            "\n",
            "terminologies\n",
            "the statistical perspective of machine learning frames data in the context of a hypothetical function (f) that the machine learning algorithm aims to learn.\n",
            "what is artificial intelligence\n",
            "chatB:  section snippets\n",
            "introduction to machine learning\n",
            "machine learning is a subfield of artificial intelligence (ai) and has evolved from pattern recognition, used to explore the structure of the data and fit into the models which can be understood and utilized by users.\n",
            "exit\n",
            "chatB:  GreaTTalk inbetween, Thanks! <3\n"
          ]
        }
      ],
      "source": [
        "import numpy as nump\n",
        "import nltk\n",
        "import string\n",
        "import random\n",
        "\n",
        "f = open('/content/mlinfotochat','r',errors = 'ignore')\n",
        "raw_doc=f.read()\n",
        "raw_doc=raw_doc.lower()\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "sent_tokens = nltk.sent_tokenize(raw_doc)\n",
        "word_tokens = nltk.word_tokenize(raw_doc)\n",
        "\n",
        "lemmer = nltk.stem.WordNetLemmatizer()\n",
        "def LemTokens(tokens):\n",
        "  return [lemmer.lemmatize(token) for token in tokens]\n",
        "remove_punct_dict = dict((ord(punct),None) for punct in string.punctuation)\n",
        "def LemNormalize(text):\n",
        "  return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))\n",
        "\n",
        "import random\n",
        "\n",
        "GREET_INPUTS = (\"hi\", \"hello\", \"hey\", \"greetings\", \"good morning\", \"good afternoon\", \"good evening\", \"yo\", \"what's up\")\n",
        "GREET_RESPONSES = (\"Hello there!\", \"Hi!\", \"Hey!\", \"Greetings!\", \"Good morning/afternoon/evening to you too!\", \"Yo!\", \"What's up?\")\n",
        "\n",
        "def greet(sentence):\n",
        "    for word in sentence.split():\n",
        "        if word.lower() in GREET_INPUTS:\n",
        "            return random.choice(GREET_RESPONSES)\n",
        "\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def response(user_response):\n",
        "  robo1_response=''\n",
        "  TfidfVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words='english')\n",
        "  tfidf = TfidfVec.fit_transform(sent_tokens)\n",
        "  vals = cosine_similarity(tfidf[-1], tfidf)\n",
        "  idx = vals.argsort()[0][-2]\n",
        "  flat = vals.flatten()\n",
        "  flat.sort()\n",
        "  req_tfidf = flat[-2]\n",
        "  if(req_tfidf==0):\n",
        "    robo1_response=robo1_response+\"Hey! I apologize, as I am still under development, I can't find anything else you asked for.\"\n",
        "    return robo1_response\n",
        "  else:\n",
        "    robo1_response = robo1_response+sent_tokens[idx]\n",
        "    return robo1_response\n",
        "\n",
        "flag = True\n",
        "print(\"Hello, I am ChatB, a AI language model here to assist you. Would you like to engage in a conversation with my counterpart,?\")\n",
        "while(flag==True):\n",
        "  user_response = input()\n",
        "  user_response=user_response.lower()\n",
        "  if(user_response!='exit'):\n",
        "    if(user_response=='thanks' or user_response=='thank you'):\n",
        "      flag=False\n",
        "      print(\"chatB:  It was my pleasure!\")\n",
        "    else:\n",
        "      if(greet(user_response)!=None):\n",
        "        print(\"chatB:  \"+greet(user_response))\n",
        "      else:\n",
        "        sent_tokens.append(user_response)\n",
        "        word_tokens=word_tokens+nltk.word_tokenize(user_response)\n",
        "        final_words=list(set(word_tokens))\n",
        "        print(\"chatB:  \",end=\"\")\n",
        "        print(response(user_response))\n",
        "        sent_tokens.remove(user_response)\n",
        "  else:\n",
        "      flag=False\n",
        "      print(\"chatB:  GreaTTalk inbetween, Thanks! <3\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMUyPkWp7v6k6sEUlJK9KBf",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}