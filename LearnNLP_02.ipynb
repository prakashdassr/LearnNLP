{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO4mr90PFeCMj3+C7v+ETAF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prakashdassr/LearnNLP/blob/main/LearnNLP_02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "rlJB9mdfYWhF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as nump\n",
        "import nltk\n",
        "import string\n",
        "import random"
      ],
      "metadata": {
        "id": "N_oXSbJNXweO"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6e1vD6uxXEer",
        "outputId": "9ec17b2c-ac09-423b-9dde-b37f104dd107"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "f = open('/content/mlinfotochat','r',errors = 'ignore')\n",
        "raw_doc=f.read()\n",
        "raw_doc=raw_doc.lower()\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "sent_tokens = nltk.sent_tokenize(raw_doc)\n",
        "word_tokens = nltk.word_tokenize(raw_doc)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent_tokens[:2] #to check sentence are tokenized"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cpERmEH-XODU",
        "outputId": "c7b7bd8f-1eb0-4948-f498-48fad1addada"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['section snippets\\nintroduction to machine learning\\nmachine learning is a subfield of artificial intelligence (ai) and has evolved from pattern recognition, used to explore the structure of the data and fit into the models which can be understood and utilized by users.',\n",
              " 'it answers the question as to how to construct a computer program using historical data, to solve a given problem and automatically improve the efficiency of the program, with experience.']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_tokens[:3] #to check words were tokenized"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDoGm4l0XQgq",
        "outputId": "7077f5ef-e69d-4772-da53-1e472e9c0410"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['section', 'snippets', 'introduction']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmer = nltk.stem.WordNetLemmatizer()\n",
        "def LemTokens(tokens):\n",
        "  return [lemmer.lemmatize(token) for token in tokens]\n",
        "remove_punct_dict = dict((ord(punct),None) for punct in string.punctuation)\n",
        "def LemNormalize(text):\n",
        "  return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))"
      ],
      "metadata": {
        "id": "8h1CvdlxXTfC"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent_tokens[:2] #checked another time"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTpjlksAXWC2",
        "outputId": "e95d0e8c-60fd-46f8-d2f7-ffb7e1b3586c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['section snippets\\nintroduction to machine learning\\nmachine learning is a subfield of artificial intelligence (ai) and has evolved from pattern recognition, used to explore the structure of the data and fit into the models which can be understood and utilized by users.',\n",
              " 'it answers the question as to how to construct a computer program using historical data, to solve a given problem and automatically improve the efficiency of the program, with experience.']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "GREET_INPUTS = (\"hi\", \"hello\", \"hey\", \"greetings\", \"good morning\", \"good afternoon\", \"good evening\")\n",
        "GREET_RESPONSES = (\"Hello there!\", \"Hi!\", \"Hey!\", \"Greetings!\", \"Good morning/afternoon/evening to you too!\")\n",
        "def greet(sentence):\n",
        "  for word in sentence.split():\n",
        "   if word.lower() in GREET_INPUTS:\n",
        "    return random.choice(GREET_RESPONSES)"
      ],
      "metadata": {
        "id": "TZ3uJrb1XYn-"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "id": "660ng5yEXaar"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def response(user_response):\n",
        "  robo1_response=''\n",
        "  TfidfVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words='english')\n",
        "  tfidf = TfidfVec.fit_transform(sent_tokens)\n",
        "  vals = cosine_similarity(tfidf[-1], tfidf)\n",
        "  idx = vals.argsort()[0][-2]\n",
        "  flat = vals.flatten()\n",
        "  flat.sort()\n",
        "  req_tfidf = flat[-2]\n",
        "  if(req_tfidf==0):\n",
        "    robo1_response=robo1_response+\"Hey! I apologize, as I am still under development, I can't find anything else you asked for.\"\n",
        "    return robo1_response\n",
        "  else:\n",
        "    robo1_response = robo1_response+sent_tokens[idx]\n",
        "    return robo1_response"
      ],
      "metadata": {
        "id": "9ztZqXvqXcMz"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GREET_INPUTS = (\"hi\", \"hello\", \"hey\", \"greetings\", \"good morning\", \"good afternoon\", \"good evening\")\n",
        "GREET_RESPONSES = (\"Hello there!\", \"Hi!\", \"Hey!\", \"Greetings!\", \"Good morning/afternoon/evening to you too!\")\n",
        "def greet(sentence):\n",
        "  for word in sentence.split():\n",
        "   if word.lower() in GREET_INPUTS:\n",
        "    return random.choice(GREET_RESPONSES)"
      ],
      "metadata": {
        "id": "P1aWYCxhXgb3"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flag = True\n",
        "print(\"Hello, I am ChatB, a AI language model here to assist you. Would you like to engage in a conversation with my counterpart,?\")\n",
        "while(flag==True):\n",
        "  user_response = input()\n",
        "  user_response=user_response.lower()\n",
        "  if(user_response!='exit'):\n",
        "    if(user_response=='thanks' or user_response=='thank you'):\n",
        "      flag=False\n",
        "      print(\"chatB:  It was my pleasure!\")\n",
        "    else:\n",
        "      if(greet(user_response)!=None):\n",
        "        print(\"chatB:  \"+ greet(user_response))\n",
        "      else:\n",
        "        sent_tokens.append(user_response)\n",
        "        word_tokens=word_tokens+nltk.word_tokenize(user_response)\n",
        "        final_words=list(set(word_tokens))\n",
        "        print(\"chatB:  \",end=\"\")\n",
        "        print(response(user_response))\n",
        "        sent_tokens.remove(user_response)\n",
        "  else:\n",
        "      flag=False\n",
        "      print(\"chatB:  GreaTTalk inbetween, Thanks! <3\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sh9MkWK-Xg8n",
        "outputId": "a5184951-183c-45a3-837f-5172e9b73a46"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, I am ChatB, a AI language model here to assist you. Would you like to engage in a conversation with my counterpart,?\n",
            "greetings\n",
            "chatB:  Hi!\n",
            "hey\n",
            "chatB:  Good morning/afternoon/evening to you too!\n",
            "exit\n",
            "chatB:  GreaTTalk inbetween, Thanks! <3\n"
          ]
        }
      ]
    }
  ]
}